{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b8c9886",
   "metadata": {},
   "source": [
    "* Lowercasing the data\n",
    "* Remove Special Characters\n",
    "* Remove Whitespace\n",
    "* Tokenize text\n",
    "* Remove stop words\n",
    "* Lemmatization/Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e99ac2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527e9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('twitter_disaster_tweet_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd1da74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this may allah for...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(' earthquake', 1)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>('', 0)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>('', 0)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive evacuation orders in california</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(' wildfires', 1)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby as smoke fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(' alaska, wildfires', 2)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this may allah for...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  all residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN    people receive evacuation orders in california    \n",
       "4   7     NaN      NaN  just got sent this photo from ruby as smoke fr...   \n",
       "\n",
       "   target  emoji_count                   hashtags mentions  \n",
       "0       1            0         (' earthquake', 1)       []  \n",
       "1       1            0                    ('', 0)       []  \n",
       "2       1            0                    ('', 0)       []  \n",
       "3       1            0          (' wildfires', 1)       []  \n",
       "4       1            0  (' alaska, wildfires', 2)       []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e6790",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b68b6fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    split=re.split(\"\\W+\",text) \n",
    "    return split\n",
    "\n",
    "data['tokenized_text']=data['text'].apply(lambda x: tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63072632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this may allah for...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(' earthquake', 1)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[our, deeds, are, the, reason, of, this, may, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>('', 0)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>('', 0)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive evacuation orders in california</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(' wildfires', 1)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[, people, receive, evacuation, orders, in, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby as smoke fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(' alaska, wildfires', 2)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, as,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this may allah for...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  all residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN    people receive evacuation orders in california    \n",
       "4   7     NaN      NaN  just got sent this photo from ruby as smoke fr...   \n",
       "\n",
       "   target  emoji_count                   hashtags mentions  \\\n",
       "0       1            0         (' earthquake', 1)       []   \n",
       "1       1            0                    ('', 0)       []   \n",
       "2       1            0                    ('', 0)       []   \n",
       "3       1            0          (' wildfires', 1)       []   \n",
       "4       1            0  (' alaska, wildfires', 2)       []   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [our, deeds, are, the, reason, of, this, may, ...  \n",
       "1      [forest, fire, near, la, ronge, sask, canada]  \n",
       "2  [all, residents, asked, to, shelter, in, place...  \n",
       "3  [, people, receive, evacuation, orders, in, ca...  \n",
       "4  [just, got, sent, this, photo, from, ruby, as,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a0884",
   "metadata": {},
   "source": [
    "### Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18c0f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "print(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3f6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text=[word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "data['clean']=data['tokenized_text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a4f85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this may allah for...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(' earthquake', 1)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[our, deeds, are, the, reason, of, this, may, ...</td>\n",
       "      <td>[deeds, reason, may, allah, forgive, us]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>('', 0)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>('', 0)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
       "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive evacuation orders in california</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(' wildfires', 1)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[, people, receive, evacuation, orders, in, ca...</td>\n",
       "      <td>[, people, receive, evacuation, orders, califo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby as smoke fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(' alaska, wildfires', 2)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, as,...</td>\n",
       "      <td>[got, sent, photo, ruby, smoke, pours, school, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this may allah for...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  all residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN    people receive evacuation orders in california    \n",
       "4   7     NaN      NaN  just got sent this photo from ruby as smoke fr...   \n",
       "\n",
       "   target  emoji_count                   hashtags mentions  \\\n",
       "0       1            0         (' earthquake', 1)       []   \n",
       "1       1            0                    ('', 0)       []   \n",
       "2       1            0                    ('', 0)       []   \n",
       "3       1            0          (' wildfires', 1)       []   \n",
       "4       1            0  (' alaska, wildfires', 2)       []   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [our, deeds, are, the, reason, of, this, may, ...   \n",
       "1      [forest, fire, near, la, ronge, sask, canada]   \n",
       "2  [all, residents, asked, to, shelter, in, place...   \n",
       "3  [, people, receive, evacuation, orders, in, ca...   \n",
       "4  [just, got, sent, this, photo, from, ruby, as,...   \n",
       "\n",
       "                                               clean  \n",
       "0           [deeds, reason, may, allah, forgive, us]  \n",
       "1      [forest, fire, near, la, ronge, sask, canada]  \n",
       "2  [residents, asked, shelter, place, notified, o...  \n",
       "3  [, people, receive, evacuation, orders, califo...  \n",
       "4   [got, sent, photo, ruby, smoke, pours, school, ]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ba7f6",
   "metadata": {},
   "source": [
    "### Lemmatization / Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76d130b",
   "metadata": {},
   "source": [
    "Stemming and Lemmatizing is the process of reducing a word to its root form. The main purpose is to reduce variations of the same word, thereby reducing the corpus of words we include in the model. The difference between stemming and lemmatizing is that, stemming chops off the end of the word without taking into consideration the context of the word. Whereas, Lemmatizing considers the context of the word and shortens the word into its root form based on the dictionary definition. Stemming is a faster process compared to Lemmantizing. Hence, it a trade-off between speed and accuracy.\n",
    "\n",
    "Let’s consider the word “belief” for example. The different variations of believe can be believing, believed, believes, and believe ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605c9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a89b08ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "believ\n",
      "believ\n",
      "believ\n",
      "believ\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('believe'))\n",
    "print(ps.stem('believing'))\n",
    "print(ps.stem('believed'))\n",
    "print(ps.stem('believes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933d107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4ff25d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "believe\n",
      "believing\n",
      "believed\n",
      "belief\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "lemmatizer=nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize('believe'))\n",
    "print(lemmatizer.lemmatize('believing'))\n",
    "print(lemmatizer.lemmatize('believed'))\n",
    "print(lemmatizer.lemmatize('believes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcf71feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(word_list):\n",
    "    lemmatized_output = [lemmatizer.lemmatize(w) for w in word_list]\n",
    "    return lemmatized_output\n",
    "\n",
    "\n",
    "data['clean_lemma']=data['clean'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c29fa1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('twitter_disaster_tweet_preprocess', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b2f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
